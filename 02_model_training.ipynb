{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turned-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import json\n",
    "from os.path import exists\n",
    "import joblib\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6003ae3-c7c8-4954-a127-010db7265a1b",
   "metadata": {},
   "source": [
    "## Defining function used for training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "weighted-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_filename(basename):\n",
    "    \"\"\"Creates unique filename to prevent overwriting\n",
    "    file when exporting trained model.\n",
    "    \"\"\"\n",
    "    counter=0\n",
    "    name = '{}_{}'.format(basename, counter)  # filename in format <basename>_<number>\n",
    "    # Adds +1 to <number> until it gets unique filename\n",
    "    while exists('models/{}.model'.format(name)):\n",
    "        counter +=1\n",
    "        name = '{}_{}'.format(basename, counter)\n",
    "        \n",
    "    return name\n",
    "\n",
    "\n",
    "def get_X_y_log(df, feats):\n",
    "    \"\"\"Creates feature matrix, target and logarihtmic vector for model training.\"\"\"\n",
    "    X = df[feats].values\n",
    "    y = df['price'].values\n",
    "    y_log = np.log(y)    \n",
    "    return X, y_log\n",
    "  \n",
    "\n",
    "def get_feats(df):\n",
    "    \"\"\"Creates training features by taking all number and boolean columns \n",
    "    from provided dataframe, reduced by those in blacklist.\n",
    "    \"\"\"       \n",
    "    blacklist = [\n",
    "        'price',\n",
    "        'id', \n",
    "        'price_m2',\n",
    "        'floors_in_building'\n",
    "        ]    \n",
    "                         \n",
    "    num_bool_feats = df.select_dtypes(['number', 'bool'])\n",
    "    return [x for x in num_bool_feats if x not in blacklist]\n",
    "    \n",
    "    \n",
    "def default_model():   \n",
    "    \"\"\"Returns CatBoostRegressor model with specific hyper parameters\"\"\"\n",
    "    model_params = dict(\n",
    "        max_depth=8,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.3,\n",
    "        random_state=0,\n",
    "        silent=True,\n",
    "        )\n",
    "    return catboost.CatBoostRegressor(**model_params)\n",
    "    \n",
    "    \n",
    "def train_model(df, info=True):\n",
    "    \"\"\"Trains and returns Catboost Regressor model\"\"\"\n",
    "    \n",
    "    # Removes from training data possible target variable leaks.\n",
    "    df_train = df[ df['price'].notnull() ].fillna(-1)\n",
    "        \n",
    "    # Gets training features.\n",
    "    feats = get_feats(df_train)\n",
    "    \n",
    "    # Gets X and y (feature matrix and target vector). \n",
    "    X, y_log = get_X_y_log(df_train, feats)\n",
    "    \n",
    "    # Model training.\n",
    "    model = default_model()\n",
    "    model.fit(X, y_log)\n",
    "    \n",
    "    if info:\n",
    "        print(f' Number of feats: {len(feats)}')        \n",
    "        print()\n",
    "        print(f'FEATS: \\n {feats}\\n')\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "def export_model(model, basename):  \n",
    "    \"\"\"Exports trained model to \"models\" folder\"\"\"    \n",
    "    filename = get_model_filename(basename)\n",
    "    joblib.dump(model, \"models/{}.model\".format(filename))\n",
    "    return 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda23c5a-5f55-4720-8344-d399a69cb03f",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fda647c5-3218-453f-84e0-ab43d15d536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46489, 53)\n"
     ]
    }
   ],
   "source": [
    "df_org = pd.read_hdf('data/train_property.h5')\n",
    "\n",
    "# External city and province data (Wikipedia)\n",
    "city_stats = pd.read_csv('external_data/city_stats_wiki.csv')\n",
    "city_stats.drop('Województwo', axis=1, inplace=True)\n",
    "city_stats.columns = ['city', 'county', 'city_area', 'city_population', 'city_density']\n",
    "\n",
    "province_stats = pd.read_csv('external_data/province_stats_wiki.csv')\n",
    "province_stats.drop('Lp.', axis=1, inplace=True)\n",
    "province_stats.columns = ['province', 'province_population', 'province_men_population', 'province_women_population']\n",
    "\n",
    "print(df_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0c932c-0b98-41d7-9a9d-7de9705ca344",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d189582e-33d2-4439-9f1b-ea29422be5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess features to get desirable, better intuitive format when inputing data\n",
    "    for predictions\"\"\"    \n",
    "\n",
    "    # Defins features that will be required for predictions.\n",
    "    required_feats = [    \n",
    "        \"area\",\n",
    "        \"rooms\",\n",
    "        \"location\",\n",
    "        'floor',\n",
    "        'floors_in_building',\n",
    "        'rok budowy',\n",
    "        'czynsz',        \n",
    "        'is_primary_market',\n",
    "        'is_private',\n",
    "        'rodzaj zabudowy',\n",
    "        'materiał budynku',\n",
    "        'okna',\n",
    "        'stan wykończenia',\n",
    "        'ogrzewanie',\n",
    "        'forma własności',\n",
    "        'system alarmowy',\n",
    "        'rolety antywłamaniowe',\n",
    "        'drzwi / okna antywłamaniowe',\n",
    "    ]\n",
    "\n",
    "    required_training_feats = ['price'] + required_feats\n",
    "\n",
    "    def parse_area(val):\n",
    "        \"\"\"Parses \"area\" feature from object/string to numeric value.\"\"\"    \n",
    "        if isinstance(val, int): return val\n",
    "        if isinstance(val, float): return val\n",
    "        return val.split('m')[0].replace(',','.').replace(' ','')\n",
    "\n",
    "    def parse_czynsz(val):\n",
    "        \"\"\"Parses \"czynsz\" feature object/string to numeric value.\"\"\"\n",
    "        if isinstance(val, int): return val\n",
    "        if isinstance(val, float): return val\n",
    "\n",
    "        if val[-1] == 'ł':\n",
    "            return float(val.split('zł')[0].replace(' ', '').replace(',','.'))\n",
    "        if val[-1] == 'r':\n",
    "            return float(val.split('eur')[0].replace(' ', '').replace(',','.'))*4.5\n",
    "\n",
    "    def parse_floors_in_building(val):\n",
    "        \"\"\"Parses \"floors_in_building\" feature from object/string to numeric value.\"\"\"\n",
    "        if isinstance(val, int): return -1\n",
    "        if isinstance(val, float): return -1    \n",
    "        return int(val.replace(')','').split()[1])\n",
    "\n",
    "    def parse_is_private(val):\n",
    "        if val in [0, 1]:\n",
    "            return bool(val)\n",
    "        return -1\n",
    "    \n",
    "\n",
    "    df = df[ required_training_feats ].copy()\n",
    "\n",
    "    df['area'] = df['area'].map(parse_area)\n",
    "    df['czynsz'] = df['czynsz'].map(parse_czynsz)\n",
    "    df['floors_in_building'] = df['floors_in_building'].map(parse_floors_in_building)\n",
    "    df['is_private'] = df['is_private'].map(parse_is_private)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8b8b9510-7923-4a1b-b2fb-2afccf8a69ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46489, 19)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre = preprocess_data(df_org)\n",
    "df_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ad8238ab-256b-43dc-91a1-98b2914f0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"Main feature engineering function. Returned dataframe is ready to model training.\"\"\"\n",
    "    \n",
    "    def parse_location_city(val):\n",
    "        \"\"\"Using external data from wikipedia checks if value parsed from location feature is city.\"\"\"\n",
    "        all_city = city_stats['city'].to_list()\n",
    "        for city_ in reversed(val):\n",
    "        # \"Józefów\" apears more then one time on on all cities list and \"Dobra\" appears also as a street name.\n",
    "        # I decided to exclude them, but it can be improved.\n",
    "            if city_ in ['Dobra', 'Józefów']:\n",
    "                continue\n",
    "            if city_ in all_city:\n",
    "                    return city_\n",
    "        return 'other' \n",
    "    \n",
    "    \n",
    "    def normalize_build_year(year):\n",
    "        \"\"\"Normalize 'build_year' feature\"\"\"\n",
    "        years = [1970, 1980, 1990, 2000, 2005, 2010, 2012, 2014, 2016, 2017]\n",
    "        if year < 1970: return 1900\n",
    "        if year > 2017: return 2018\n",
    "    \n",
    "        for idx in range(len(years) - 1):\n",
    "            if years[idx+1] > year >= years[idx]:\n",
    "                return years[idx]\n",
    "    \n",
    "\n",
    "    def normalize_floors_in_building(val):\n",
    "        \"\"\"Cap max floors in building number to control outliers\"\"\"\n",
    "        floor = float(val)\n",
    "        return floor if floor < 20 else 25\n",
    "    \n",
    "\n",
    "    def categorize_and_export_as_json(df, featname):\n",
    "        \"\"\"Creates and export as json, dictionary with category labels for selected feature\"\"\"\n",
    "        cat_dict = dict(zip(df['{}'.format(featname)].drop_duplicates().values, df['{}'.format(featname)].drop_duplicates().factorize()[0]))\n",
    "        cat_dict = {key:int(value) for key, value in cat_dict.items()}        \n",
    "        with open('model_predict_data/cat_dict_{}.txt'.format(featname), 'w') as file:\n",
    "            file.write(json.dumps(cat_dict))\n",
    "        print(f'{file.name} saved.')\n",
    "            \n",
    "        return df[featname].map(cat_dict)\n",
    "    \n",
    "    \n",
    "    def df_groupby_feat_and_export_to_csv(df, groupby_feats, feat):\n",
    "        \"\"\"Retuns aggregated feature by selected one or more features and export it to csv\"\"\"\n",
    "        agg_params={\n",
    "            'mean_{}_{}'.format('_'.join(groupby_feats), feat): (feat, 'mean'),\n",
    "            'median_{}_{}'.format('_'.join(groupby_feats), feat): (feat, 'median'),\n",
    "         }\n",
    "        groupby_df = df[groupby_feats + [feat]].groupby(groupby_feats).agg(\n",
    "            **agg_params\n",
    "        ).reset_index()\n",
    "        filename = 'groupby_{}_{}.csv'.format('_'.join(groupby_feats), feat)\n",
    "\n",
    "        groupby_df.to_csv('model_predict_data/{}'.format(filename), index=False)\n",
    "        print(f'{filename} saved.')\n",
    "\n",
    "        return groupby_df\n",
    "    \n",
    "    \n",
    "    def is_primary_market_conc(df, feat):\n",
    "        \"\"\"Concatenate \"is_primary_market\" with other feature and categorize the results.\n",
    "        Dictionary with category labels is exported for prediction part\"\"\"\n",
    "        df['is_primary_market_{}'.format(feat)] = df[ ['is_primary_market', feat] ].apply(\n",
    "            lambda x: '{}_{}'.format(x['is_primary_market'], x[feat]), axis=1\n",
    "        )\n",
    "\n",
    "        df['is_primary_market_{}_cat'.format(feat)] = categorize_and_export_as_json(df, 'is_primary_market_{}'.format(feat))\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Area\n",
    "    df['area_num'] = df.area.astype(float)\n",
    "    area_num_99 = np.percentile(df['area_num'], 99)\n",
    "    df['area_norm'] = df['area_num'].map(lambda x: x if x <= area_num_99 else area_num_99)\n",
    "    df['area_num_log'] = np.log(df['area_num'])\n",
    "    df['price_m2'] = df['price'] / df['area_num'] \n",
    "    \n",
    "    # Rooms\n",
    "    df['area_per_room'] = df['area_norm'] / df[\"rooms\"]    \n",
    "\n",
    "    # Location \n",
    "    province_cities = ['Białystok', 'Bydgoszcz', 'Gdańsk', 'Gorzów Wielkopolski', 'Katowice', 'Kielce', 'Kraków', 'Lublin',\n",
    "    'Łódź', 'Olsztyn', 'Opole', 'Poznań', 'Rzeszów', 'Szczecin', 'Toruń', 'Warszawa', 'Wrocław', 'Zielona Góra']\n",
    "    \n",
    "    df['province'] = df['location'].map(lambda x: x[0])\n",
    "    df['city'] = df['location'].map(parse_location_city)\n",
    "    df['province_city'] = df['city'].isin(province_cities)\n",
    "    \n",
    "    # Merging main dataframe with external data about cities.\n",
    "    if 'city_area' not in df.columns:\n",
    "        df = pd.merge(df, city_stats, on='city', how='left')\n",
    "    # Merging main dataframe with external data about provinces.    \n",
    "    if 'province_population' not in df.columns:\n",
    "        df = pd.merge(df, province_stats, on='province', how='left')\n",
    "        \n",
    "    \"\"\"'Location' feature is list cointaining elements describing property location in order\n",
    "    from general to specyfic, which could be [<province>, <county>, <city>, <district> and <street>].\n",
    "    \"\"\"    \n",
    "    for i in range(5):        \n",
    "        # We can assume that \"loc1\" is likely province, \"loc2\" is likely county and so on.\n",
    "        df[\"loc{}\".format(i)] = df[\"location\"].map(lambda x: x[i] if len(x) > i else \"\")      \n",
    "    \n",
    "    df['loc01'] = df['loc0'] + df['loc1']\n",
    "    df['loc012'] = df['loc0'] + df['loc1'] + df['loc2']\n",
    "    df['loc12'] = df['loc1'] + df['loc2']\n",
    "    \n",
    "    # Categorize location features\n",
    "    for i in range(5):\n",
    "        df[\"loc{}_cat\".format(i)] = categorize_and_export_as_json(df, 'loc{}'.format(i))\n",
    "    df[\"loc01_cat\"] = categorize_and_export_as_json(df, 'loc01')\n",
    "    df[\"loc012_cat\"] = categorize_and_export_as_json(df, 'loc012')\n",
    "    df[\"loc12_cat\"] = categorize_and_export_as_json(df, 'loc12')\n",
    "    \n",
    "    df['city_cat'] = categorize_and_export_as_json(df, 'city')\n",
    "    df['county_cat'] = categorize_and_export_as_json(df, 'county')\n",
    "    df['province_cat'] = categorize_and_export_as_json(df, 'province')\n",
    "  \n",
    "    big_cities = {'Poznań', 'Sopot', 'Wrocław', 'Kraków', 'Gdańsk', 'Gdynia', 'Opole', 'Katowice',  'Częstochowa', 'Szczecin', 'Kalisz', 'Łódź', 'Olsztyn', 'Warszawa'}\n",
    "    for city in big_cities:\n",
    "        df[city] = df['city'] == city\n",
    "        df['big_city'] = df['city'].map(lambda x: x in big_cities)\n",
    "        \n",
    "    \n",
    "    # loc1 is likely to be \"city\", and loc2 is likely to be \"district\", so with combining this two\n",
    "    # we could get for example: WrocławKrzyki, WarszawaŚródmieście, SopotGórny and so on.\n",
    "    df_val_cnts = df['loc12'].value_counts()\n",
    "    \n",
    "    # We takes combinations only if they occur more then 100 times in dataset.\n",
    "    loc12_vals = set(df_val_cnts[ df_val_cnts > 100].index.values)\n",
    "    for item in loc12_vals:\n",
    "        df[item] = df['loc12'] == item \n",
    "    \n",
    "    # Floor\n",
    "    floors_dict = {'parter': 0, '> 10': 11, 'poddasze': -2, 'suterena': -1}\n",
    "    df['floor_num'] = df['floor'].map(lambda x: floors_dict.get(x, x)).fillna(-10).astype('int')\n",
    "    \n",
    "    # Floors_in_building\n",
    "    df['floors_in_building_num'] = df['floors_in_building'].map(normalize_floors_in_building)\n",
    "   \n",
    "\n",
    "    # \"price\" aggregations    \n",
    "    groupby_city_price = df_groupby_feat_and_export_to_csv(df, ['city'], 'price')       \n",
    "    if 'median_city_price' not in df:\n",
    "        df = pd.merge(df, groupby_city_price, on='city', how='left')\n",
    "        \n",
    "    groupby_county_price = df_groupby_feat_and_export_to_csv(df, ['county'], 'price')   \n",
    "    if 'median_county_price' not in df:\n",
    "        df = pd.merge(df, groupby_county_price, on='county', how='left')\n",
    "  \n",
    "   \n",
    "    # is_primary_market\n",
    "    df = is_primary_market_conc(df, 'rooms')\n",
    "    df = is_primary_market_conc(df, 'city')\n",
    "    df = is_primary_market_conc(df, 'rodzaj zabudowy') \n",
    "    \n",
    "    # \"price_m2\" aggregations for concateneted is_primary_market with other features.   \n",
    "    groupby_price_m2 = df_groupby_feat_and_export_to_csv(df, ['is_primary_market_rooms'], 'price_m2')\n",
    "    if 'median_is_primary_market_rooms_price_m2' not in df:\n",
    "        df = pd.merge(df, groupby_price_m2, on='is_primary_market_rooms', how='left')\n",
    "        \n",
    "    groupby_price_m2 = df_groupby_feat_and_export_to_csv(df, ['is_primary_market_rodzaj zabudowy'], 'price_m2')\n",
    "    if 'median_is_primary_market_rodzaj zabudowy_price_m2' not in df:\n",
    "        df = pd.merge(df, groupby_price_m2, on='is_primary_market_rodzaj zabudowy', how='left')\n",
    "   \n",
    "    # rok budowy            \n",
    "    df['build_year'] = df['rok budowy'].fillna(-1).astype('int')   \n",
    "    df[\"build_year_norm\"] = df[\"build_year\"].map(normalize_build_year)\n",
    "    \n",
    "    df['security'] = df['system alarmowy'] | df['rolety antywłamaniowe'] | df['drzwi / okna antywłamaniowe']\n",
    "    \n",
    "    cat_feats = {         \n",
    "        \"materiał budynku\": \"build_material_cat\",\n",
    "        \"okna\": \"window_cat\",\n",
    "        \"stan wykończenia\": \"property_completion_cat\",\n",
    "        \"rodzaj zabudowy\": \"property_type_cat\",\n",
    "        \"ogrzewanie\": \"property_heating_cat\",\n",
    "        \"forma własności\": \"own_property_cat\"\n",
    "         }    \n",
    "    \n",
    "    for feat_name, feat_new_name in cat_feats.items():    \n",
    "        df[feat_new_name] = categorize_and_export_as_json(df, feat_name)\n",
    "      \n",
    "        #OHE\n",
    "        df_dummies = pd.get_dummies(df[feat_name])\n",
    "        df_dummies.columns = ['{0}_{1}'.format(feat_new_name, x) for x in df_dummies.columns]\n",
    "        df = pd.concat([df, df_dummies], axis=1)     \n",
    "    \n",
    "\n",
    "    print('Done')    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fb2888fa-0643-4cda-89c6-92e3ad63c67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_predict_data/cat_dict_loc0.txt saved.\n",
      "model_predict_data/cat_dict_loc1.txt saved.\n",
      "model_predict_data/cat_dict_loc2.txt saved.\n",
      "model_predict_data/cat_dict_loc3.txt saved.\n",
      "model_predict_data/cat_dict_loc4.txt saved.\n",
      "model_predict_data/cat_dict_loc01.txt saved.\n",
      "model_predict_data/cat_dict_loc012.txt saved.\n",
      "model_predict_data/cat_dict_loc12.txt saved.\n",
      "model_predict_data/cat_dict_city.txt saved.\n",
      "model_predict_data/cat_dict_county.txt saved.\n",
      "model_predict_data/cat_dict_province.txt saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kowsc\\AppData\\Local\\Temp/ipykernel_22716/480045570.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[item] = df['loc12'] == item\n",
      "C:\\Users\\kowsc\\AppData\\Local\\Temp/ipykernel_22716/480045570.py:137: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['floor_num'] = df['floor'].map(lambda x: floors_dict.get(x, x)).fillna(-10).astype('int')\n",
      "C:\\Users\\kowsc\\AppData\\Local\\Temp/ipykernel_22716/480045570.py:140: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['floors_in_building_num'] = df['floors_in_building'].map(normalize_floors_in_building)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupby_city_price.csv saved.\n",
      "groupby_county_price.csv saved.\n",
      "model_predict_data/cat_dict_is_primary_market_rooms.txt saved.\n",
      "model_predict_data/cat_dict_is_primary_market_city.txt saved.\n",
      "model_predict_data/cat_dict_is_primary_market_rodzaj zabudowy.txt saved.\n",
      "groupby_is_primary_market_rooms_price_m2.csv saved.\n",
      "groupby_is_primary_market_rodzaj zabudowy_price_m2.csv saved.\n",
      "model_predict_data/cat_dict_materiał budynku.txt saved.\n",
      "model_predict_data/cat_dict_okna.txt saved.\n",
      "model_predict_data/cat_dict_stan wykończenia.txt saved.\n",
      "model_predict_data/cat_dict_rodzaj zabudowy.txt saved.\n",
      "model_predict_data/cat_dict_ogrzewanie.txt saved.\n",
      "model_predict_data/cat_dict_forma własności.txt saved.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_fe = feature_engineering(df_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "04bcb30c-9d92-4d7e-81f1-c6ada539e352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of feats: 190\n",
      "\n",
      "FEATS: \n",
      " ['rooms', 'czynsz', 'is_primary_market', 'system alarmowy', 'rolety antywłamaniowe', 'drzwi / okna antywłamaniowe', 'area_num', 'area_norm', 'area_num_log', 'area_per_room', 'province_city', 'city_area', 'city_population', 'city_density', 'province_population', 'province_men_population', 'province_women_population', 'loc0_cat', 'loc1_cat', 'loc2_cat', 'loc3_cat', 'loc4_cat', 'loc01_cat', 'loc012_cat', 'loc12_cat', 'city_cat', 'county_cat', 'province_cat', 'Poznań', 'big_city', 'Wrocław', 'Kraków', 'Kalisz', 'Gdynia', 'Opole', 'Szczecin', 'Gdańsk', 'Sopot', 'Częstochowa', 'Olsztyn', 'Łódź', 'Warszawa', 'Katowice', 'GdańskJasień', 'kołobrzeskiKołobrzeg', 'WarszawaMokotów', 'WarszawaBielany', 'ŁódźŚródmieście', 'WarszawaOchota', 'GdańskStare Miasto', 'KrakówNowa Huta', 'BydgoszczFordon', 'świdnickiŚwidnica', 'WarszawaBiałołęka', 'ToruńChełmińskie Przedmieście', 'GdańskMorena', 'BydgoszczBartodzieje', 'Zielona Góra', 'WarszawaWilanów', 'WrocławKrzyki', 'KrakówCzyżyny', 'SzczecinCentrum', 'PoznańWinogrady', 'PoznańRataje', 'KrakówPodgórze', 'gdańskiPruszcz Gdański', 'LublinCzuby', 'BydgoszczCentrum', 'BydgoszczSzwederowo', 'PoznańNaramowice', 'KrakówStare Miasto', 'KatowicePiotrowice', 'KrakówKazimierz', 'KatowiceOsiedle Tysiąclecia', 'stargardzkiStargard', 'BydgoszczWyżyny', 'KrakówPrądnik Czerwony', 'Rzeszów', 'WrocławStare Miasto', 'WarszawaPraga-Południe', 'lubińskiLubin', 'TychyŻwaków', 'KatowiceOsiedle Paderewskiego', 'tatrzańskiZakopane', 'KrakówWola Justowska', 'KatowiceBrynów', 'GdańskWrzeszcz', 'ŁódźGórna', 'wejherowskiRumia', 'WrocławFabryczna', 'KatowiceJózefowiec', 'KrakówGrzegórzki', 'WrocławKlecina', 'KatowiceDolina Trzech Stawów', 'LublinŚródmieście', 'WarszawaWola', 'głogowskiGłogów', 'RzeszówDrabinianka', 'LublinLSM', 'ŁódźPolesie', 'KrakówRuczaj', 'LublinWrotków', 'GdyniaŚródmieście', 'WarszawaBemowo', 'BydgoszczKapuściska', 'tczewskiTczew', 'wielickiWieliczka', 'PoznańGrunwald', 'KielceŚlichowice', 'KielceCentrum', 'KatowiceŚródmieście', 'KrakówDębniki', 'GdyniaOrłowo', 'PoznańNowe Miasto', 'KrakówŚródmieście', 'GdańskŚródmieście', 'SopotDolny', 'GdańskŁostowice', 'WarszawaPraga-Północ', 'RzeszówSłocina', 'WrocławPsie Pole', 'KrakówKrowodrza', 'GdańskPrzymorze', 'KrakówBronowice', 'PoznańWilda', 'ToruńMokre', 'ełckiEłk', 'ŁódźBałuty', 'wołomińskiZąbki', 'WrocławŚródmieście', 'WarszawaUrsynów', 'KrakówPrądnik Biały', 'KrakówBieżanów-Prokocim', 'WarszawaŚródmieście', 'KatowiceWełnowiec', 'floor_num', 'floors_in_building_num', 'mean_city_price', 'median_city_price', 'mean_county_price', 'median_county_price', 'is_primary_market_rooms_cat', 'is_primary_market_city_cat', 'is_primary_market_rodzaj zabudowy_cat', 'mean_is_primary_market_rooms_price_m2', 'median_is_primary_market_rooms_price_m2', 'mean_is_primary_market_rodzaj zabudowy_price_m2', 'median_is_primary_market_rodzaj zabudowy_price_m2', 'build_year', 'build_year_norm', 'security', 'build_material_cat', 'build_material_cat_beton', 'build_material_cat_beton komórkowy', 'build_material_cat_cegła', 'build_material_cat_drewno', 'build_material_cat_inne', 'build_material_cat_keramzyt', 'build_material_cat_pustak', 'build_material_cat_silikat', 'build_material_cat_wielka płyta', 'build_material_cat_żelbet', 'window_cat', 'window_cat_aluminiowe', 'window_cat_drewniane', 'window_cat_plastikowe', 'property_completion_cat', 'property_completion_cat_do remontu', 'property_completion_cat_do wykończenia', 'property_completion_cat_do zamieszkania', 'property_type_cat', 'property_type_cat_apartamentowiec', 'property_type_cat_blok', 'property_type_cat_dom wolnostojący', 'property_type_cat_kamienica', 'property_type_cat_loft', 'property_type_cat_plomba', 'property_type_cat_szeregowiec', 'property_heating_cat', 'property_heating_cat_elektryczne', 'property_heating_cat_gazowe', 'property_heating_cat_inne', 'property_heating_cat_kotłownia', 'property_heating_cat_miejskie', 'property_heating_cat_piece kaflowe', 'own_property_cat', 'own_property_cat_pełna własność', 'own_property_cat_spółdzielcze wł. z kw', 'own_property_cat_spółdzielcze własnościowe', 'own_property_cat_udział']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train_model(df_fe)\n",
    "export_model(model, 'test_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
