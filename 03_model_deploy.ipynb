{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civic-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pressed-presentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prediction_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prediction_server.py\n",
    "# -*- coding:utf-8 -*-\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "model = joblib.load('models/test_model_0.model')\n",
    "\n",
    "# External city and province data (Wikipedia)\n",
    "city_stats = pd.read_csv('external_data/city_stats_wiki.csv')\n",
    "city_stats.drop('Województwo', axis=1, inplace=True)\n",
    "city_stats.columns = ['city', 'county', 'city_area', 'city_population', 'city_density']\n",
    "\n",
    "province_stats = pd.read_csv('external_data/province_stats_wiki.csv')\n",
    "province_stats.drop('Lp.', axis=1, inplace=True)\n",
    "province_stats.columns = ['province', 'province_population', 'province_men_population', 'province_women_population']\n",
    "\n",
    "\n",
    "def fe(df):\n",
    "    \"\"\"Main feature engineering function. Returned dataframe is ready to prediction.\"\"\"\n",
    "    \n",
    "    def parse_location_city(val):\n",
    "        \"\"\"Using external data from wikipedia checks if value parsed from location feature is city.\"\"\"\n",
    "        all_city = city_stats['city'].to_list()\n",
    "        for city_ in reversed(val):\n",
    "        # \"Józefów\" apears more then one time on on all cities list and \"Dobra\" appears also as a street name.\n",
    "        # I decided to exclude them, but it can be improved.\n",
    "            if city_ in ['Dobra', 'Józefów']:\n",
    "                continue\n",
    "            if city_ in all_city:\n",
    "                    return city_\n",
    "        return 'other' \n",
    "    \n",
    "    def normalize_build_year(year):\n",
    "        \"\"\"Normalize 'build_year' feature\"\"\"\n",
    "        years = [1970, 1980, 1990, 2000, 2005, 2010, 2012, 2014, 2016, 2017]\n",
    "        if year < 1970: return 1900\n",
    "        if year > 2017: return 2018\n",
    "    \n",
    "        for idx in range(len(years) - 1):\n",
    "            if years[idx+1] > year >= years[idx]:\n",
    "                return years[idx]\n",
    "    \n",
    "\n",
    "    def normalize_floors_in_building(val):\n",
    "        \"\"\"Cap max floors in building number to control outliers\"\"\"\n",
    "        floor = float(val)\n",
    "        return floor if floor < 20 else 25\n",
    "    \n",
    "          \n",
    "    def categorize_from_json(df, featname):\n",
    "        \"\"\"Import dictionary with label encoding used for training model\n",
    "        and used it to categorize dataframe feature\"\"\"\n",
    "        with open('model_predict_data/cat_dict_{}.txt'.format(featname), 'r', encoding='cp437',\n",
    "                 errors='ignore') as file:\n",
    "            cat_dict = json.load(file)\n",
    "            \n",
    "        return df[featname].map(cat_dict)\n",
    "\n",
    "    \n",
    "    def import_aggregated_df_from_csv(groupby_feats, feat):\n",
    "        \"\"\"Import aggregations used for training model\"\"\"        \n",
    "        filename = 'groupby_{}_{}.csv'.format('_'.join(groupby_feats), feat)\n",
    "        with open('model_predict_data/{}'.format(filename), 'r', encoding='cp437',\n",
    "                 errors='ignore') as file:\n",
    "            groupby_df = pd.read_csv(file)\n",
    "        return groupby_df\n",
    "    \n",
    "  \n",
    "    def is_primary_market_conc(df, feat):\n",
    "        \"\"\"Concatenate \"is_primary_market\" with other feature and categorize the results.\n",
    "        Imported dictionary with category labels was used for training model\"\"\"\n",
    "        df['is_primary_market_{}'.format(feat)] = df[ ['is_primary_market', feat] ].apply(\n",
    "            lambda x: '{}_{}'.format(x['is_primary_market'], x[feat]), axis=1\n",
    "        )\n",
    "\n",
    "        df['is_primary_market_{}_cat'.format(feat)] = categorize_from_json(df, 'is_primary_market_{}'.format(feat))\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "    # Area\n",
    "    df['area_num'] = df.area.astype(float)\n",
    "    area_num_99 = np.percentile(df['area_num'], 99)\n",
    "    df['area_norm'] = df['area_num'].map(lambda x: x if x <= area_num_99 else area_num_99)\n",
    "    df['area_num_log'] = np.log(df['area_num'])    \n",
    "    \n",
    "    # Rooms\n",
    "    df['area_per_room'] = df['area_norm'] / df[\"rooms\"]    \n",
    "\n",
    "    # Location \n",
    "    province_cities = ['Białystok', 'Bydgoszcz', 'Gdańsk', 'Gorzów Wielkopolski', 'Katowice', 'Kielce', 'Kraków', 'Lublin',\n",
    "    'Łódź', 'Olsztyn', 'Opole', 'Poznań', 'Rzeszów', 'Szczecin', 'Toruń', 'Warszawa', 'Wrocław', 'Zielona Góra']\n",
    "    \n",
    "    df['province'] = df['location'].map(lambda x: x[0])\n",
    "    df['city'] = df['location'].map(parse_location_city)\n",
    "    df['province_city'] = df['city'].isin(province_cities)\n",
    "    \n",
    "    # Merging main dataframe with external data about cities.\n",
    "    if 'city_area' not in df.columns:\n",
    "        df = pd.merge(df, city_stats, on='city', how='left')\n",
    "    # Merging main dataframe with external data about provinces.    \n",
    "    if 'province_population' not in df.columns:\n",
    "        df = pd.merge(df, province_stats, on='province', how='left')\n",
    "        \n",
    "    \n",
    "    \"\"\"'Location' feature is list cointaining elements describing property location in order\n",
    "    from general to specyfic, which could be [<province>, <county>, <city>, <district> and <street>].\n",
    "    \"\"\"    \n",
    "    for i in range(5):        \n",
    "        # We can assume that \"loc1\" is likely province, \"loc2\" is likely county and so on.\n",
    "        df[\"loc{}\".format(i)] = df[\"location\"].map(lambda x: x[i] if len(x) > i else \"\")      \n",
    "    \n",
    "    df['loc01'] = df['loc0'] + df['loc1']\n",
    "    df['loc012'] = df['loc0'] + df['loc1'] + df['loc2']\n",
    "    df['loc12'] = df['loc1'] + df['loc2']\n",
    "    \n",
    "    # Categorize location features\n",
    "    for i in range(5):\n",
    "        df[\"loc{}_cat\".format(i)] = categorize_from_json(df, 'loc{}'.format(i))\n",
    "    df[\"loc01_cat\"] = categorize_from_json(df, 'loc01')\n",
    "    df[\"loc012_cat\"] = categorize_from_json(df, 'loc012')\n",
    "    df[\"loc12_cat\"] = categorize_from_json(df, 'loc12')\n",
    "    \n",
    "    df['city_cat'] = categorize_from_json(df, 'city')\n",
    "    df['county_cat'] = categorize_from_json(df, 'county')\n",
    "    df['province_cat'] = categorize_from_json(df, 'province')\n",
    "  \n",
    "    big_cities = {'Poznań', 'Sopot', 'Wrocław', 'Kraków', 'Gdańsk', 'Gdynia', 'Opole', 'Katowice',  'Częstochowa', 'Szczecin', 'Kalisz', 'Łódź', 'Olsztyn', 'Warszawa'}\n",
    "    for city in big_cities:\n",
    "        df[city] = df['city'] == city\n",
    "        df['big_city'] = df['city'].map(lambda x: x in big_cities)\n",
    "    \n",
    "    # loc1 is likely to be \"city\", and loc2 is likely to be \"district\", so with combining this two\n",
    "    # we could get for example: WrocławKrzyki, WarszawaŚródmieście, SopotGórny and so on.\n",
    "    df_val_cnts = df['loc12'].value_counts()\n",
    "    \n",
    "    # We takes combinations only if they occur more then 100 times in dataset.\n",
    "    loc12_vals = set(df_val_cnts[ df_val_cnts > 100].index.values)\n",
    "    for item in loc12_vals:\n",
    "        df[item] = df['loc12'] == item \n",
    "        \n",
    "    # Floor\n",
    "    floors_dict = {'parter': 0, '> 10': 11, 'poddasze': -2, 'suterena': -1}\n",
    "    df['floor_num'] = df['floor'].map(lambda x: floors_dict.get(x, x)).fillna(-10).astype('int')\n",
    "    \n",
    "    # Floors_in_building\n",
    "    df['floors_in_building_num'] = df['floors_in_building'].map(normalize_floors_in_building)\n",
    "   \n",
    "    # \"price\" aggregations    \n",
    "    groupby_city_price = import_aggregated_df_from_csv(['city'], 'price')       \n",
    "    if 'median_city_price' not in df:\n",
    "        df = pd.merge(df, groupby_city_price, on='city', how='left')\n",
    "        \n",
    "    groupby_county_price = import_aggregated_df_from_csv(['county'], 'price')   \n",
    "    if 'median_county_price' not in df:\n",
    "        df = pd.merge(df, groupby_county_price, on='county', how='left')\n",
    "\n",
    "    # is_primary_market\n",
    "    df = is_primary_market_conc(df, 'rooms')\n",
    "    df = is_primary_market_conc(df, 'city')\n",
    "    df = is_primary_market_conc(df, 'rodzaj zabudowy') \n",
    "    \n",
    "    # \"price_m2\" aggregations for concateneted is_primary_market with other features.   \n",
    "    groupby_price_m2 = import_aggregated_df_from_csv(['is_primary_market_rooms'], 'price_m2')\n",
    "    if 'median_is_primary_market_rooms_price_m2' not in df:\n",
    "        df = pd.merge(df, groupby_price_m2, on='is_primary_market_rooms', how='left')\n",
    "        \n",
    "    groupby_price_m2 = import_aggregated_df_from_csv(['is_primary_market_rodzaj zabudowy'], 'price_m2')\n",
    "    if 'median_is_primary_market_rodzaj zabudowy_price_m2' not in df:\n",
    "        df = pd.merge(df, groupby_price_m2, on='is_primary_market_rodzaj zabudowy', how='left')\n",
    "        \n",
    "    \n",
    "    # rok budowy            \n",
    "    df['build_year'] = df['rok budowy'].fillna(-1).astype('int')   \n",
    "    df[\"build_year_norm\"] = df[\"build_year\"].map(normalize_build_year)\n",
    "    \n",
    "    df['security'] = df['system alarmowy'] | df['rolety antywłamaniowe'] | df['drzwi / okna antywłamaniowe']\n",
    "    \n",
    "    cat_feats = {         \n",
    "        \"materiał budynku\": \"build_material_cat\",\n",
    "        \"okna\": \"window_cat\",\n",
    "        \"stan wykończenia\": \"property_completion_cat\",\n",
    "        \"rodzaj zabudowy\": \"property_type_cat\",\n",
    "        \"ogrzewanie\": \"property_heating_cat\",\n",
    "        \"forma własności\": \"own_property_cat\"\n",
    "         }    \n",
    "    \n",
    "    for feat_name, feat_new_name in cat_feats.items():    \n",
    "        df[feat_new_name] = categorize_from_json(df, feat_name)\n",
    "      \n",
    "        #OHE\n",
    "        df_dummies = pd.get_dummies(df[feat_name])\n",
    "        df_dummies.columns = ['{0}_{1}'.format(feat_new_name, x) for x in df_dummies.columns]\n",
    "        df = pd.concat([df, df_dummies], axis=1)     \n",
    "    \n",
    "\n",
    "    print('Done')   \n",
    "    return df\n",
    "\n",
    "home_template = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>Real Estate Price Prediction by Bartosz Kowalik</title>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "[TEMPORARY TEMPLATE]\n",
    "<h1>Real estate price prediction by <a href=\"https://www.linkedin.com/in/bartosz-kowalik-5756ba1b3\">Bartosz Kowalik</a></h1></br>\n",
    "\n",
    "<h2>\n",
    "<a href=\"https://docs.google.com/spreadsheets/d/1jgPEtyx0QhLS91Z51rJ8HMKu22zxUFoLuuMuUrFyn-o\">This is link</a>\n",
    "to Google sheet with implemented script, that connects it with our prediction server. </br>\n",
    "You can make real estate price prediction directly in your Google sheet. </br></br>\n",
    "\n",
    "SETUP: </br>\n",
    "[TO BE COMPLETED]</br></br>\n",
    "\n",
    "Input format:</br>\n",
    "[TO BE COMPLETED] </br></br>\n",
    "\n",
    "<a href=\"https://github.com/Twarzy/property_forecast_excel_deploy\">PROJECT GITHUB PAGE</a></br></br>\n",
    "<h2>\n",
    "\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def main_page():\n",
    "    return home_template\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def get_forecast():\n",
    "    \"\"\"Run server. After POST data in specyfic format it returns predictions\"\"\"\n",
    "    \n",
    "    try:        \n",
    "        df = pd.DataFrame(request.json)\n",
    "        print(df)\n",
    "        if 'location' in df:\n",
    "            df['location'] = df['location'].map(lambda x: x.split(','))\n",
    "   \n",
    "\n",
    "        df_fe = fe(df)\n",
    "    \n",
    "        feats = ['rooms', 'czynsz', 'is_primary_market', 'system alarmowy', 'rolety antywłamaniowe', 'drzwi / okna antywłamaniowe', 'area_num', 'area_norm', 'area_num_log', 'area_per_room', 'province_city', 'city_area', 'city_population', 'city_density', 'province_population', 'province_men_population', 'province_women_population', 'loc0_cat', 'loc1_cat', 'loc2_cat', 'loc3_cat', 'loc4_cat', 'loc01_cat', 'loc012_cat', 'loc12_cat', 'city_cat', 'county_cat', 'province_cat', 'Poznań', 'big_city', 'Wrocław', 'Kraków', 'Kalisz', 'Gdynia', 'Opole', 'Szczecin', 'Gdańsk', 'Sopot', 'Częstochowa', 'Olsztyn', 'Łódź', 'Warszawa', 'Katowice', 'GdańskJasień', 'kołobrzeskiKołobrzeg', 'WarszawaMokotów', 'WarszawaBielany', 'ŁódźŚródmieście', 'WarszawaOchota', 'GdańskStare Miasto', 'KrakówNowa Huta', 'BydgoszczFordon', 'świdnickiŚwidnica', 'WarszawaBiałołęka', 'ToruńChełmińskie Przedmieście', 'GdańskMorena', 'BydgoszczBartodzieje', 'Zielona Góra', 'WarszawaWilanów', 'WrocławKrzyki', 'KrakówCzyżyny', 'SzczecinCentrum', 'PoznańWinogrady', 'PoznańRataje', 'KrakówPodgórze', 'gdańskiPruszcz Gdański', 'LublinCzuby', 'BydgoszczCentrum', 'BydgoszczSzwederowo', 'PoznańNaramowice', 'KrakówStare Miasto', 'KatowicePiotrowice', 'KrakówKazimierz', 'KatowiceOsiedle Tysiąclecia', 'stargardzkiStargard', 'BydgoszczWyżyny', 'KrakówPrądnik Czerwony', 'Rzeszów', 'WrocławStare Miasto', 'WarszawaPraga-Południe', 'lubińskiLubin', 'TychyŻwaków', 'KatowiceOsiedle Paderewskiego', 'tatrzańskiZakopane', 'KrakówWola Justowska', 'KatowiceBrynów', 'GdańskWrzeszcz', 'ŁódźGórna', 'wejherowskiRumia', 'WrocławFabryczna', 'KatowiceJózefowiec', 'KrakówGrzegórzki', 'WrocławKlecina', 'KatowiceDolina Trzech Stawów', 'LublinŚródmieście', 'WarszawaWola', 'głogowskiGłogów', 'RzeszówDrabinianka', 'LublinLSM', 'ŁódźPolesie', 'KrakówRuczaj', 'LublinWrotków', 'GdyniaŚródmieście', 'WarszawaBemowo', 'BydgoszczKapuściska', 'tczewskiTczew', 'wielickiWieliczka', 'PoznańGrunwald', 'KielceŚlichowice', 'KielceCentrum', 'KatowiceŚródmieście', 'KrakówDębniki', 'GdyniaOrłowo', 'PoznańNowe Miasto', 'KrakówŚródmieście', 'GdańskŚródmieście', 'SopotDolny', 'GdańskŁostowice', 'WarszawaPraga-Północ', 'RzeszówSłocina', 'WrocławPsie Pole', 'KrakówKrowodrza', 'GdańskPrzymorze', 'KrakówBronowice', 'PoznańWilda', 'ToruńMokre', 'ełckiEłk', 'ŁódźBałuty', 'wołomińskiZąbki', 'WrocławŚródmieście', 'WarszawaUrsynów', 'KrakówPrądnik Biały', 'KrakówBieżanów-Prokocim', 'WarszawaŚródmieście', 'KatowiceWełnowiec', 'floor_num', 'floors_in_building_num', 'mean_city_price', 'median_city_price', 'mean_county_price', 'median_county_price', 'is_primary_market_rooms_cat', 'is_primary_market_city_cat', 'is_primary_market_rodzaj zabudowy_cat', 'mean_is_primary_market_rooms_price_m2', 'median_is_primary_market_rooms_price_m2', 'mean_is_primary_market_rodzaj zabudowy_price_m2', 'median_is_primary_market_rodzaj zabudowy_price_m2', 'build_year', 'build_year_norm', 'security', 'build_material_cat', 'build_material_cat_beton', 'build_material_cat_beton komórkowy', 'build_material_cat_cegła', 'build_material_cat_drewno', 'build_material_cat_inne', 'build_material_cat_keramzyt', 'build_material_cat_pustak', 'build_material_cat_silikat', 'build_material_cat_wielka płyta', 'build_material_cat_żelbet', 'window_cat', 'window_cat_aluminiowe', 'window_cat_drewniane', 'window_cat_plastikowe', 'property_completion_cat', 'property_completion_cat_do remontu', 'property_completion_cat_do wykończenia', 'property_completion_cat_do zamieszkania', 'property_type_cat', 'property_type_cat_apartamentowiec', 'property_type_cat_blok', 'property_type_cat_dom wolnostojący', 'property_type_cat_kamienica', 'property_type_cat_loft', 'property_type_cat_plomba', 'property_type_cat_szeregowiec', 'property_heating_cat', 'property_heating_cat_elektryczne', 'property_heating_cat_gazowe', 'property_heating_cat_inne', 'property_heating_cat_kotłownia', 'property_heating_cat_miejskie', 'property_heating_cat_piece kaflowe', 'own_property_cat', 'own_property_cat_pełna własność', 'own_property_cat_spółdzielcze wł. z kw', 'own_property_cat_spółdzielcze własnościowe', 'own_property_cat_udział']\n",
    "        \n",
    "        # Temporary bug fix - start\n",
    "        for feat in feats:\n",
    "            if feat not in df_fe.columns:\n",
    "                df_fe[feat] = 0\n",
    "        # Temporary bug fix - end\n",
    "        \n",
    "        X = df_fe[feats].values\n",
    "        y_pred = np.exp(model.predict(X))\n",
    "        \n",
    "        return jsonify(prices=[float(x) for x in y_pred], status='ok')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return jsonify(message='something is going wrong', status='error')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8051, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034c673-9f08-4daa-9865-96792a0504bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prediction_server.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
